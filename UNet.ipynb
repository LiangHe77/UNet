{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=3),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,int(in_channels/2),kernel_size=3),\n",
    "            nn.BatchNorm2d(int(in_channels/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(int(in_channels/2),out_channels,kernel_size=3),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(mode='bilinear',scale_factor=2),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = BasicConv(1,64)\n",
    "        self.conv2 = BasicConv(64,128)\n",
    "        self.conv3 = BasicConv(128,256)\n",
    "        self.conv4 = BasicConv(256,512)\n",
    "        \n",
    "        self.conv5 = BasicConv2(1024,256)\n",
    "        self.conv6 = BasicConv2(512,128)\n",
    "        self.conv7 = BasicConv2(256,64)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.upsample1 = UpSample()\n",
    "        self.upsample2 = UpSample()\n",
    "        self.upsample3 = UpSample()\n",
    "        self.upsample4 = UpSample()\n",
    "\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.Conv2d(512,1024,kernel_size=3),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1024,512,kernel_size=3),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.end = nn.Sequential(\n",
    "            nn.Conv2d(128,64,kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,2,kernel_size=1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_64_568 = self.conv1(x)\n",
    "        x1_dim = x_64_568.shape[2]\n",
    "        x_64_284 = self.pool(x_64_568)\n",
    "        \n",
    "        x_128_280 = self.conv2(x_64_284)\n",
    "        x2_dim = x_128_280.shape[2]\n",
    "        x_128_140 = self.pool(x_128_280)\n",
    "        \n",
    "        x_256_136 = self.conv3(x_128_140)\n",
    "        x3_dim = x_256_136.shape[2]\n",
    "        x_256_68 = self.pool(x_256_136)\n",
    "        \n",
    "        x_512_64 = self.conv4(x_256_68)\n",
    "        x4_dim = x_512_64.shape[2]\n",
    "        x_512_32 = self.pool(x_512_64)\n",
    "        \n",
    "        x_512_28 = self.transition(x_512_32)\n",
    "        x_512_56 = self.upsample1(x_512_28)\n",
    "        \n",
    "        lower = int((x4_dim-x_512_56.shape[2])/2)\n",
    "        upper = int(x4_dim-lower)\n",
    "        x_1024_56 = torch.cat((x_512_56,(x_512_64)[:,:,lower:upper,lower:upper]),1)\n",
    "        x_256_52 = self.conv5(x_1024_56)\n",
    "        x_256_104 = self.upsample2(x_256_52)\n",
    "        \n",
    "        lower = int((x3_dim-x_256_104.shape[2])/2)\n",
    "        upper = int(x3_dim-lower)\n",
    "        x_512_104 = torch.cat((x_256_104,(x_256_136)[:,:,lower:upper,lower:upper]),1)\n",
    "        x_128_100 = self.conv6(x_512_104)\n",
    "        x_128_200 = self.upsample3(x_128_100)\n",
    "        \n",
    "        lower = int((x2_dim-x_128_200.shape[2])/2)\n",
    "        upper = int(x2_dim-lower)\n",
    "        x_256_200 = torch.cat((x_128_200,(x_128_280)[:,:,lower:upper,lower:upper]),1)\n",
    "        x_64_196 = self.conv7(x_256_200)\n",
    "        x_64_392 = self.upsample4(x_64_196)\n",
    "        \n",
    "        lower = int((x1_dim-x_64_392.shape[2])/2)\n",
    "        upper = int(x1_dim-lower)\n",
    "        x_128_392 = torch.cat((x_64_392,(x_64_568)[:,:,lower:upper,lower:upper]),1)\n",
    "        out = self.end(x_128_392)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 386, 386])\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    input = torch.randn(1,1,572,572)\n",
    "    net = UNet()\n",
    "    output = net(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
